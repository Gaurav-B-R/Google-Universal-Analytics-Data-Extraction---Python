{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##### Code By Gaurav B R\n",
        "##### Email: gauravhsn8@gmail.com"
      ],
      "metadata": {
        "id": "BMLaVJxwkQOL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run the below 4 codes to install the required modules."
      ],
      "metadata": {
        "id": "NjHG5hseEGzi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install google-api-python-client"
      ],
      "metadata": {
        "id": "-xuatwJVDiOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install oauth2client"
      ],
      "metadata": {
        "id": "jH-8e0D9FARi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandas"
      ],
      "metadata": {
        "id": "AP2dDAyPE_8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install requests"
      ],
      "metadata": {
        "id": "3cXzD-0qE_yh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Metrics Data Extraction (Date wise)\n",
        "### All metrics will be downloaded in one dataset.\n",
        "- VIEW_ID:- Add your Universal Analytics view id/property id.\n",
        "- startDate:- Add the start date in 'YYYY-MM-DD' format.\n",
        "- endDate:- Add the end date in 'YYYY-MM-DD' format.\n",
        "- Add the local file path at last for where you want to save the extracted data. Ex: \"C:/Users/Gaurav R/Downloads/Metrics_Data.csv\"\n",
        "\n",
        "### Note:-\n",
        "- Upload the \"MetricsDimensions.csv\" in your working environment before you run the below programs. Do not change the name of the above file. You can find this file here:-\n",
        "- Upload the json key file in your working environment and add that file name inside the string for the variable \"KEY_FILE_LOCATION\".\n",
        "- Refer this link to get your json key file:- https://bit.ly/43nS9jH"
      ],
      "metadata": {
        "id": "jUzOwIPSBCO9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_NAICIiq3-U"
      },
      "outputs": [],
      "source": [
        "\"\"\"Hello Analytics Reporting API V4.\"\"\"\n",
        "\n",
        "from apiclient.discovery import build\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "import pandas as pd\n",
        "import requests\n",
        "\n",
        "SCOPES = ['https://www.googleapis.com/auth/analytics.readonly']\n",
        "KEY_FILE_LOCATION = '<uploaded_json_key_file_name>'\n",
        "VIEW_ID = '123456789'\n",
        "startDate = 'YYYY-MM-DD'\n",
        "endDate = 'YYYY-MM-DD'\n",
        "Metrics = pd.read_csv('MetricsDimensions.csv')['Metrics']\n",
        "Dimensions = pd.read_csv('MetricsDimensions.csv')['Dimensions']\n",
        "\n",
        "def initialize_analyticsreporting():\n",
        "  \"\"\"Initializes an Analytics Reporting API V4 service object.\n",
        "\n",
        "  Returns:\n",
        "    An authorized Analytics Reporting API V4 service object.\n",
        "  \"\"\"\n",
        "  credentials = ServiceAccountCredentials.from_json_keyfile_name(\n",
        "      KEY_FILE_LOCATION, SCOPES)\n",
        "\n",
        "  # Build the service object.\n",
        "  analytics = build('analyticsreporting', 'v4', credentials=credentials)\n",
        "\n",
        "  return analytics\n",
        "\n",
        "def get_report(analytics, page_token=None):\n",
        "    \"\"\"Queries the Analytics Reporting API V4.\n",
        "\n",
        "    Args:\n",
        "        analytics: An authorized Analytics Reporting API V4 service object.\n",
        "        page_token: Token for retrieving the next page of data (optional).\n",
        "    Returns:\n",
        "        The Analytics Reporting API V4 response.\n",
        "    \"\"\"\n",
        "    report_request = {\n",
        "        'viewId': VIEW_ID,\n",
        "        'dateRanges': [{'startDate': startDate, 'endDate': endDate}],\n",
        "        'metrics': [{'expression': 'ga:users'}],\n",
        "        'dimensions': [{'name': 'ga:pagePath'}, {'name': 'ga:date'}],\n",
        "        'pageSize': 1000000\n",
        "    }\n",
        "\n",
        "    if page_token:\n",
        "        report_request['pageToken'] = page_token\n",
        "\n",
        "    return analytics.reports().batchGet(\n",
        "        body={\n",
        "            'reportRequests': [report_request]\n",
        "        }\n",
        "    ).execute()\n",
        "\n",
        "\n",
        "def process_response(response):\n",
        "    \"\"\"Processes the Analytics Reporting API V4 response and returns a Pandas DataFrame.\n",
        "\n",
        "    Args:\n",
        "        response: An Analytics Reporting API V4 response.\n",
        "\n",
        "    Returns:\n",
        "        A Pandas DataFrame containing the processed data.\n",
        "    \"\"\"\n",
        "    data = []\n",
        "    for report in response.get('reports', []):\n",
        "        columnHeader = report.get('columnHeader', {})\n",
        "        dimensionHeaders = columnHeader.get('dimensions', [])\n",
        "        metricHeaders = columnHeader.get('metricHeader', {}).get('metricHeaderEntries', [])\n",
        "\n",
        "        for row in report.get('data', {}).get('rows', []):\n",
        "            dimensions = row.get('dimensions', [])\n",
        "            dateRangeValues = row.get('metrics', [])\n",
        "\n",
        "            row_data = []\n",
        "            for header, dimension in zip(dimensionHeaders, dimensions):\n",
        "                row_data.append(dimension)\n",
        "\n",
        "            for i, values in enumerate(dateRangeValues):\n",
        "                for metricHeader, value in zip(metricHeaders, values.get('values')):\n",
        "                    row_data.append(value)\n",
        "\n",
        "            data.append(row_data)\n",
        "\n",
        "    # Create a Pandas DataFrame\n",
        "    df = pd.DataFrame(data, columns=dimensionHeaders + [header['name'] for header in metricHeaders])\n",
        "    return df\n",
        "\n",
        "\n",
        "analytics = initialize_analyticsreporting()\n",
        "response = get_report(analytics)\n",
        "df = process_response(response)\n",
        "\n",
        "# Check if there are more pages\n",
        "next_page_token = response.get('reports', [{}])[0].get('nextPageToken')\n",
        "while next_page_token:\n",
        "  response = get_report(analytics, next_page_token)\n",
        "  df1 = process_response(response)\n",
        "  next_page_token = response.get('reports', [{}])[0].get('nextPageToken')\n",
        "  df=pd.concat([df,df1],axis=0)\n",
        "df['Merged (ga:pagePath + ga:date)']=df['ga:pagePath']+' '+df['ga:date']\n",
        "\n",
        "\n",
        "def get_report1(analytics, page_token=None, a='hello'):\n",
        "    \"\"\"Queries the Analytics Reporting API V4.\n",
        "\n",
        "    Args:\n",
        "        analytics: An authorized Analytics Reporting API V4 service object.\n",
        "        page_token: Token for retrieving the next page of data (optional).\n",
        "    Returns:\n",
        "        The Analytics Reporting API V4 response.\n",
        "    \"\"\"\n",
        "    report_request = {\n",
        "        'viewId': VIEW_ID,\n",
        "        'dateRanges': [{'startDate': startDate, 'endDate': endDate}],\n",
        "        'metrics': [{'expression': 'ga:users'}, {'expression': a}],\n",
        "        'dimensions': [{'name': 'ga:pagePath'}, {'name': 'ga:date'}],\n",
        "        'pageSize': 100000\n",
        "    }\n",
        "\n",
        "    if page_token:\n",
        "        report_request['pageToken'] = page_token\n",
        "\n",
        "    return analytics.reports().batchGet(\n",
        "        body={\n",
        "            'reportRequests': [report_request]\n",
        "        }\n",
        "    ).execute()\n",
        "\n",
        "\n",
        "def process_response1(response):\n",
        "    \"\"\"Processes the Analytics Reporting API V4 response and returns a Pandas DataFrame.\n",
        "\n",
        "    Args:\n",
        "        response: An Analytics Reporting API V4 response.\n",
        "\n",
        "    Returns:\n",
        "        A Pandas DataFrame containing the processed data.\n",
        "    \"\"\"\n",
        "    data = []\n",
        "    for report in response.get('reports', []):\n",
        "        columnHeader = report.get('columnHeader', {})\n",
        "        dimensionHeaders = columnHeader.get('dimensions', [])\n",
        "        metricHeaders = columnHeader.get('metricHeader', {}).get('metricHeaderEntries', [])\n",
        "\n",
        "        for row in report.get('data', {}).get('rows', []):\n",
        "            dimensions = row.get('dimensions', [])\n",
        "            dateRangeValues = row.get('metrics', [])\n",
        "\n",
        "            row_data = []\n",
        "            for header, dimension in zip(dimensionHeaders, dimensions):\n",
        "                row_data.append(dimension)\n",
        "\n",
        "            for i, values in enumerate(dateRangeValues):\n",
        "                for metricHeader, value in zip(metricHeaders, values.get('values')):\n",
        "                    row_data.append(value)\n",
        "\n",
        "            data.append(row_data)\n",
        "\n",
        "    # Create a Pandas DataFrame\n",
        "    df1 = pd.DataFrame(data, columns=dimensionHeaders + [header['name'] for header in metricHeaders])\n",
        "    return df1\n",
        "\n",
        "\n",
        "metrics_error=[]\n",
        "for i in Metrics:\n",
        "  try:\n",
        "    analytics = initialize_analyticsreporting()\n",
        "    response = get_report1(analytics, a=i)\n",
        "    df1 = process_response1(response)\n",
        "\n",
        "    # Check if there are more pages\n",
        "    next_page_token = response.get('reports', [{}])[0].get('nextPageToken')\n",
        "    while next_page_token:\n",
        "      response = get_report1(analytics, next_page_token, a=i)\n",
        "      df2 = process_response1(response)\n",
        "      next_page_token = response.get('reports', [{}])[0].get('nextPageToken')\n",
        "      df1=pd.concat([df1,df2],axis=0)\n",
        "    df1['Merged (ga:pagePath + ga:date)']=df1['ga:pagePath']+' '+df1['ga:date']\n",
        "    df1=df1.drop(columns=['ga:pagePath', 'ga:date', 'ga:users'])\n",
        "    df=pd.merge(df, df1, on='Merged (ga:pagePath + ga:date)', how='outer')\n",
        "  except Exception as e:\n",
        "    metrics_error.extend([i])\n",
        "    continue\n",
        "df\n",
        "df.to_csv(\"<Add_the_file_path_here>/Metrics_Data.csv\") # Add the local file path here where you want to save the extracted data. Ex: \"C:/Users/Gaurav R/Downloads/Metrics_Data.csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dimensions Data Extraction\n",
        "### Each dimension will be extracted in a seperate dataset and will be saved in the file path which you provide below.\n",
        "- VIEW_ID:- Add your Universal Analytics view id/property id.\n",
        "- startDate:- Add the start date in 'YYYY-MM-DD' format.\n",
        "- endDate:- Add the end date in 'YYYY-MM-DD' format.\n",
        "- Add the local file path at last for where you want to save the extracted data. Ex: \"C:/Users/Gaurav R/Downloads/.......\""
      ],
      "metadata": {
        "id": "FxUpn4J9Ferg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Hello Analytics Reporting API V4.\"\"\"\n",
        "\n",
        "from apiclient.discovery import build\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "import pandas as pd\n",
        "import requests\n",
        "\n",
        "\n",
        "SCOPES = ['https://www.googleapis.com/auth/analytics.readonly']\n",
        "KEY_FILE_LOCATION = '<uploaded_json_key_file_name>'\n",
        "VIEW_ID = '123456789'\n",
        "startDate = 'YYYY-MM-DD'\n",
        "endDate = 'YYYY-MM-DD'\n",
        "Metrics = pd.read_csv('MetricsDimensions.csv')['Metrics']\n",
        "Dimensions = pd.read_csv('MetricsDimensions.csv')['Dimensions']\n",
        "\n",
        "def initialize_analyticsreporting():\n",
        "  \"\"\"Initializes an Analytics Reporting API V4 service object.\n",
        "\n",
        "  Returns:\n",
        "    An authorized Analytics Reporting API V4 service object.\n",
        "  \"\"\"\n",
        "  credentials = ServiceAccountCredentials.from_json_keyfile_name(\n",
        "      KEY_FILE_LOCATION, SCOPES)\n",
        "\n",
        "  # Build the service object.\n",
        "  analytics = build('analyticsreporting', 'v4', credentials=credentials)\n",
        "\n",
        "  return analytics\n",
        "\n",
        "def process_response(response):\n",
        "    \"\"\"Processes the Analytics Reporting API V4 response and returns a Pandas DataFrame.\n",
        "\n",
        "    Args:\n",
        "        response: An Analytics Reporting API V4 response.\n",
        "\n",
        "    Returns:\n",
        "        A Pandas DataFrame containing the processed data.\n",
        "    \"\"\"\n",
        "    data = []\n",
        "    for report in response.get('reports', []):\n",
        "        columnHeader = report.get('columnHeader', {})\n",
        "        dimensionHeaders = columnHeader.get('dimensions', [])\n",
        "        metricHeaders = columnHeader.get('metricHeader', {}).get('metricHeaderEntries', [])\n",
        "\n",
        "        for row in report.get('data', {}).get('rows', []):\n",
        "            dimensions = row.get('dimensions', [])\n",
        "            dateRangeValues = row.get('metrics', [])\n",
        "\n",
        "            row_data = []\n",
        "            for header, dimension in zip(dimensionHeaders, dimensions):\n",
        "                row_data.append(dimension)\n",
        "\n",
        "            for i, values in enumerate(dateRangeValues):\n",
        "                for metricHeader, value in zip(metricHeaders, values.get('values')):\n",
        "                    row_data.append(value)\n",
        "\n",
        "            data.append(row_data)\n",
        "\n",
        "    # Create a Pandas DataFrame\n",
        "    df = pd.DataFrame(data, columns=dimensionHeaders + [header['name'] for header in metricHeaders])\n",
        "    return df\n",
        "\n",
        "def get_report(analytics, page_token=None, a='hello'):\n",
        "    \"\"\"Queries the Analytics Reporting API V4.\n",
        "\n",
        "    Args:\n",
        "        analytics: An authorized Analytics Reporting API V4 service object.\n",
        "        page_token: Token for retrieving the next page of data (optional).\n",
        "    Returns:\n",
        "        The Analytics Reporting API V4 response.\n",
        "    \"\"\"\n",
        "    report_request = {\n",
        "        'viewId': VIEW_ID,\n",
        "        'dateRanges': [{'startDate': startDate, 'endDate': endDate}],\n",
        "        'metrics': [{'expression': 'ga:users'}, {'expression': a}],\n",
        "        'dimensions': [{'name': 'ga:pagePath'}, {'name': 'ga:date'}, {'name': 'ga:dateHourMinute'}],\n",
        "        'pageSize': 100000\n",
        "    }\n",
        "\n",
        "    if page_token:\n",
        "        report_request['pageToken'] = page_token\n",
        "\n",
        "    return analytics.reports().batchGet(\n",
        "        body={\n",
        "            'reportRequests': [report_request]\n",
        "        }\n",
        "    ).execute()\n",
        "\n",
        "metrics_error=[]\n",
        "for i in Metrics:\n",
        "    try:\n",
        "      analytics = initialize_analyticsreporting()\n",
        "      response = get_report(analytics, a=i)\n",
        "      df = process_response(response)\n",
        "\n",
        "      # Check if there are more pages\n",
        "      next_page_token = response.get('reports', [{}])[0].get('nextPageToken')\n",
        "      while next_page_token:\n",
        "        response = get_report(analytics, next_page_token, a=i)\n",
        "        df1 = process_response(response)\n",
        "        next_page_token = response.get('reports', [{}])[0].get('nextPageToken')\n",
        "        df=pd.concat([df,df1],axis=0)\n",
        "      df['Merged (ga:pagePath + ga:date)']=df['ga:pagePath']+' '+df['ga:date']\n",
        "      df.to_csv(f\"<Add_the_folder_path_here>/{i[3:]}.csv\") # Add the local file path here where you want to save the extracted data. Ex: \"C:/Users/Gaurav R/Downloads/{i[3:]}.csv\"\n",
        "    except Exception as e:\n",
        "      metrics_error.extend([i])\n",
        "      continue"
      ],
      "metadata": {
        "id": "3FBBKA5-Fgox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Metrics Data Extraction (Date_Hour_Minute wise)\n",
        "### Each metrics will be extracted in a seperate dataset and will be saved in the file path which you provide below.\n",
        "- VIEW_ID:- Add your Universal Analytics view id/property id.\n",
        "- startDate:- Add the start date in 'YYYY-MM-DD' format.\n",
        "- endDate:- Add the end date in 'YYYY-MM-DD' format.\n",
        "- Add the local file path at last for where you want to save the extracted data. Ex: \"C:/Users/Gaurav R/Downloads/.......\""
      ],
      "metadata": {
        "id": "s3issScFVPLb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Hello Analytics Reporting API V4.\"\"\"\n",
        "\n",
        "from apiclient.discovery import build\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "import pandas as pd\n",
        "import requests\n",
        "\n",
        "\n",
        "SCOPES = ['https://www.googleapis.com/auth/analytics.readonly']\n",
        "KEY_FILE_LOCATION = '<uploaded_json_key_file_name>'\n",
        "VIEW_ID = '123456789'\n",
        "startDate = 'YYYY-MM-DD'\n",
        "endDate = 'YYYY-MM-DD'\n",
        "Metrics = pd.read_csv('MetricsDimensions.csv')['Metrics']\n",
        "Dimensions = pd.read_csv('MetricsDimensions.csv')['Dimensions']\n",
        "\n",
        "def initialize_analyticsreporting():\n",
        "  \"\"\"Initializes an Analytics Reporting API V4 service object.\n",
        "\n",
        "  Returns:\n",
        "    An authorized Analytics Reporting API V4 service object.\n",
        "  \"\"\"\n",
        "  credentials = ServiceAccountCredentials.from_json_keyfile_name(\n",
        "      KEY_FILE_LOCATION, SCOPES)\n",
        "\n",
        "  # Build the service object.\n",
        "  analytics = build('analyticsreporting', 'v4', credentials=credentials)\n",
        "\n",
        "  return analytics\n",
        "\n",
        "def process_response(response):\n",
        "    \"\"\"Processes the Analytics Reporting API V4 response and returns a Pandas DataFrame.\n",
        "\n",
        "    Args:\n",
        "        response: An Analytics Reporting API V4 response.\n",
        "\n",
        "    Returns:\n",
        "        A Pandas DataFrame containing the processed data.\n",
        "    \"\"\"\n",
        "    data = []\n",
        "    for report in response.get('reports', []):\n",
        "        columnHeader = report.get('columnHeader', {})\n",
        "        dimensionHeaders = columnHeader.get('dimensions', [])\n",
        "        metricHeaders = columnHeader.get('metricHeader', {}).get('metricHeaderEntries', [])\n",
        "\n",
        "        for row in report.get('data', {}).get('rows', []):\n",
        "            dimensions = row.get('dimensions', [])\n",
        "            dateRangeValues = row.get('metrics', [])\n",
        "\n",
        "            row_data = []\n",
        "            for header, dimension in zip(dimensionHeaders, dimensions):\n",
        "                row_data.append(dimension)\n",
        "\n",
        "            for i, values in enumerate(dateRangeValues):\n",
        "                for metricHeader, value in zip(metricHeaders, values.get('values')):\n",
        "                    row_data.append(value)\n",
        "\n",
        "            data.append(row_data)\n",
        "\n",
        "    # Create a Pandas DataFrame\n",
        "    df = pd.DataFrame(data, columns=dimensionHeaders + [header['name'] for header in metricHeaders])\n",
        "    return df\n",
        "\n",
        "def get_report(analytics, page_token=None, a='hello'):\n",
        "    \"\"\"Queries the Analytics Reporting API V4.\n",
        "\n",
        "    Args:\n",
        "        analytics: An authorized Analytics Reporting API V4 service object.\n",
        "        page_token: Token for retrieving the next page of data (optional).\n",
        "    Returns:\n",
        "        The Analytics Reporting API V4 response.\n",
        "    \"\"\"\n",
        "    report_request = {\n",
        "        'viewId': VIEW_ID,\n",
        "        'dateRanges': [{'startDate': startDate, 'endDate': endDate}],\n",
        "        'metrics': [{'expression': 'ga:users'}, {'expression': a}],\n",
        "        'dimensions': [{'name': 'ga:pagePath'}, {'name': 'ga:date'}, {'name': 'ga:dateHourMinute'}],\n",
        "        'pageSize': 100000\n",
        "    }\n",
        "\n",
        "    if page_token:\n",
        "        report_request['pageToken'] = page_token\n",
        "\n",
        "    return analytics.reports().batchGet(\n",
        "        body={\n",
        "            'reportRequests': [report_request]\n",
        "        }\n",
        "    ).execute()\n",
        "\n",
        "metrics_error=[]\n",
        "for i in Metrics:\n",
        "    try:\n",
        "      analytics = initialize_analyticsreporting()\n",
        "      response = get_report(analytics, a=i)\n",
        "      df = process_response(response)\n",
        "\n",
        "      # Check if there are more pages\n",
        "      next_page_token = response.get('reports', [{}])[0].get('nextPageToken')\n",
        "      while next_page_token:\n",
        "        response = get_report(analytics, next_page_token, a=i)\n",
        "        df1 = process_response(response)\n",
        "        next_page_token = response.get('reports', [{}])[0].get('nextPageToken')\n",
        "        df=pd.concat([df,df1],axis=0)\n",
        "      df['Merged (ga:pagePath + ga:date)']=df['ga:pagePath']+' '+df['ga:date']\n",
        "      df.to_csv(f\"<Add_the_folder_path_here>/{i[3:]}.csv\") # Add the local file path at last for where you want to save the extracted data. Ex: \"C:/Users/Gaurav R/Downloads/{i[3:]}.csv\"\n",
        "    except Exception as e:\n",
        "      metrics_error.extend([i])\n",
        "      continue"
      ],
      "metadata": {
        "id": "I1o8sHYXVYot"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}